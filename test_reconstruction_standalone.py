#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„é‡å»ºæµ‹è¯•ï¼Œä½¿ç”¨ improved_exporter.py ä¸­çš„ InputFlattener
"""

import sys
import torch

# Add mmdetection3d to path for accessing data structures
sys.path.insert(0, '/Users/kevinteng/src/kevinteng525/open-mmlab/mmdetection3d')
sys.path.insert(0, '/Users/kevinteng/src/kevinteng525/open-mmlab/refined')

# Import InputFlattener from improved_exporter.py
from improved_exporter import InputFlattener


def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("=" * 60)
    print("åŸºæœ¬åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    # ç®€å•æµ‹è¯•æ•°æ®
    data = {
        'tensor1': torch.randn(10, 5),
        'nested': {
            'tensor2': torch.randn(20, 3),
            'tensor3': torch.randn(5, 5)
        },
        'list_data': [
            torch.randn(3, 3),
            torch.randn(3, 3)
        ]
    }

    # æµ‹è¯•å±•å¹³
    flattener = InputFlattener()
    flat_tensors = flattener.analyze_and_flatten(data)

    print(f"åŸå§‹æ•°æ®: {len(flat_tensors)} ä¸ªå¼ é‡")
    for i, info in enumerate(flattener.tensor_info):
        print(f"  [{i}] {info['path']}: {info['shape']}")

    # æµ‹è¯•é‡å»º
    reconstructed = flattener.reconstruct_inputs(flat_tensors)

    # éªŒè¯
    success = True
    if torch.allclose(data['tensor1'], reconstructed['tensor1']):
        print("âœ“ tensor1 é‡å»ºæˆåŠŸ")
    else:
        print("âœ— tensor1 é‡å»ºå¤±è´¥")
        success = False

    if torch.allclose(data['nested']['tensor2'], reconstructed['nested']['tensor2']):
        print("âœ“ nested.tensor2 é‡å»ºæˆåŠŸ")
    else:
        print("âœ— nested.tensor2 é‡å»ºå¤±è´¥")
        success = False

    if torch.allclose(data['nested']['tensor3'], reconstructed['nested']['tensor3']):
        print("âœ“ nested.tensor3 é‡å»ºæˆåŠŸ")
    else:
        print("âœ— nested.tensor3 é‡å»ºå¤±è´¥")
        success = False

    if (isinstance(reconstructed['list_data'], list) and
        len(reconstructed['list_data']) == 2 and
        torch.allclose(data['list_data'][0], reconstructed['list_data'][0]) and
        torch.allclose(data['list_data'][1], reconstructed['list_data'][1])):
        print("âœ“ list_data é‡å»ºæˆåŠŸ")
    else:
        print("âœ— list_data é‡å»ºå¤±è´¥")
        success = False

    print(f"\nåŸºæœ¬åŠŸèƒ½æµ‹è¯•ç»“æœ: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}")
    return success


def test_complex_structure():
    """æµ‹è¯•å¤æ‚ç»“æ„"""
    print("\n" + "=" * 60)
    print("å¤æ‚ç»“æ„æµ‹è¯•")
    print("=" * 60)

    # å¤æ‚æµ‹è¯•æ•°æ®
    data = {
        'batch_inputs': {
            'points': [torch.randn(100, 5), torch.randn(200, 5), torch.randn(150, 5)],
            'features': torch.randn(3, 64, 32, 32),
            'metadata': {
                'batch_size': 3,
                'device': 'cuda:0'
            }
        },
        'data_samples': [
            {
                'gt_bboxes': torch.randn(10, 4),
                'gt_labels': torch.randint(0, 10, (10,)),
                'img_shape': (224, 224)
            },
            {
                'gt_bboxes': torch.randn(5, 4),
                'gt_labels': torch.randint(0, 10, (5,)),
                'img_shape': (224, 224)
            },
            {
                'gt_bboxes': torch.randn(8, 4),
                'gt_labels': torch.randint(0, 10, (8,)),
                'img_shape': (224, 224)
            }
        ]
    }

    flattener = InputFlattener()
    flat_tensors = flattener.analyze_and_flatten(data)

    print(f"å¤æ‚æ•°æ®: {len(flat_tensors)} ä¸ªå¼ é‡")
    for i, info in enumerate(flattener.tensor_info):
        print(f"  [{i}] {info['path']}: {info['shape']}")

    # é‡å»º
    reconstructed = flattener.reconstruct_inputs(flat_tensors)

    # éªŒè¯
    success = True

    # æ£€æŸ¥ batch_inputs
    if 'batch_inputs' in reconstructed:
        if 'points' in reconstructed['batch_inputs']:
            points_recon = reconstructed['batch_inputs']['points']
            if isinstance(points_recon, list) and len(points_recon) == 3:
                for i, (orig, recon) in enumerate(zip(data['batch_inputs']['points'], points_recon)):
                    if torch.allclose(orig, recon):
                        print(f"âœ“ batch_inputs.points[{i}] é‡å»ºæˆåŠŸ")
                    else:
                        print(f"âœ— batch_inputs.points[{i}] é‡å»ºå¤±è´¥")
                        success = False
            else:
                print("âœ— batch_inputs.points ç»“æ„é”™è¯¯")
                success = False
        else:
            print("âœ— batch_inputs.points ç¼ºå¤±")
            success = False

        if 'features' in reconstructed['batch_inputs']:
            if torch.allclose(data['batch_inputs']['features'], reconstructed['batch_inputs']['features']):
                print("âœ“ batch_inputs.features é‡å»ºæˆåŠŸ")
            else:
                print("âœ— batch_inputs.features é‡å»ºå¤±è´¥")
                success = False
        else:
            print("âœ— batch_inputs.features ç¼ºå¤±")
            success = False
    else:
        print("âœ— batch_inputs ç¼ºå¤±")
        success = False

    # æ£€æŸ¥ data_samples
    if 'data_samples' in reconstructed:
        data_samples_recon = reconstructed['data_samples']
        if isinstance(data_samples_recon, list) and len(data_samples_recon) == 3:
            for i in range(3):
                for key in ['gt_bboxes', 'gt_labels']:
                    if key in data_samples_recon[i]:
                        if torch.allclose(data['data_samples'][i][key], data_samples_recon[i][key]):
                            print(f"âœ“ data_samples[{i}].{key} é‡å»ºæˆåŠŸ")
                        else:
                            print(f"âœ— data_samples[{i}].{key} é‡å»ºå¤±è´¥")
                            success = False
                    else:
                        print(f"âœ— data_samples[{i}].{key} ç¼ºå¤±")
                        success = False
        else:
            print("âœ— data_samples ç»“æ„é”™è¯¯")
            success = False
    else:
        print("âœ— data_samples ç¼ºå¤±")
        success = False

    print(f"\nå¤æ‚ç»“æ„æµ‹è¯•ç»“æœ: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}")
    return success


def test_empty_and_edge_cases():
    """æµ‹è¯•ç©ºå¼ é‡å’Œè¾¹ç•Œæƒ…å†µ"""
    print("\n" + "=" * 60)
    print("è¾¹ç•Œæƒ…å†µæµ‹è¯•")
    print("=" * 60)

    test_cases = [
        {
            'name': 'åŒ…å«ç©ºå¼ é‡',
            'data': {
                'empty': torch.empty(0),
                'normal': torch.randn(5, 5)
            }
        },
        {
            'name': 'æ·±åº¦åµŒå¥—',
            'data': {
                'level1': {
                    'level2': {
                        'level3': {
                            'deep_tensor': torch.randn(2, 2)
                        }
                    }
                }
            }
        },
        {
            'name': 'æ··åˆç±»å‹',
            'data': {
                'tensor': torch.randn(3, 3),
                'string': 'test',
                'number': 42,
                'none': None,
                'list': [torch.randn(1, 1), 'text', 123]
            }
        }
    ]

    flattener = InputFlattener()
    all_success = True

    for test_case in test_cases:
        print(f"\næµ‹è¯•: {test_case['name']}")

        flat_tensors = flattener.analyze_and_flatten(test_case['data'])
        reconstructed = flattener.reconstruct_inputs(flat_tensors)

        print(f"  æå–å¼ é‡æ•°: {len(flat_tensors)}")

        # ç®€å•éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦æ²¡æœ‰ä¸¢å¤±éç©ºå¼ é‡
        manual_count = 0
        def count_non_empty_tensors(data):
            count = 0
            if isinstance(data, torch.Tensor) and data.numel() > 0:
                count += 1
            elif isinstance(data, dict):
                for v in data.values():
                    count += count_non_empty_tensors(v)
            elif isinstance(data, list) and not isinstance(data, str):
                for item in data:
                    count += count_non_empty_tensors(item)
            return count

        expected_count = count_non_empty_tensors(test_case['data'])

        if len(flat_tensors) == expected_count:
            print(f"  âœ“ å¼ é‡æ•°é‡æ­£ç¡®: {expected_count}")
        else:
            print(f"  âœ— å¼ é‡æ•°é‡é”™è¯¯: æœŸæœ› {expected_count}, å®é™… {len(flat_tensors)}")
            all_success = False

    print(f"\nè¾¹ç•Œæƒ…å†µæµ‹è¯•ç»“æœ: {'âœ… å…¨éƒ¨é€šè¿‡' if all_success else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
    return all_success


def main():
    print("InputFlattener ç‹¬ç«‹æµ‹è¯•")
    print("ä½¿ç”¨ improved_exporter.py ä¸­çš„ InputFlattener")

    results = []
    results.append(test_basic_functionality())
    results.append(test_complex_structure())
    results.append(test_empty_and_edge_cases())

    print("\n" + "=" * 60)
    print("æ€»ä½“æµ‹è¯•ç»“æœ:")
    passed = sum(results)
    total = len(results)
    print(f"é€šè¿‡: {passed}/{total}")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰ç‹¬ç«‹æµ‹è¯•é€šè¿‡ï¼")
        print("improved_exporter.py ä¸­çš„ InputFlattener åŠŸèƒ½å®Œæ•´ã€‚")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼")
        print("éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")
    print("=" * 60)


if __name__ == '__main__':
    main()